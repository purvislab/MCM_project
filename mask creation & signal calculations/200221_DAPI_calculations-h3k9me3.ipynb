{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "from skimage.external import tifffile\n",
    "from skimage.external.tifffile import imread\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "from scipy.ndimage.morphology import binary_erosion as br\n",
    "from skimage import morphology as skmor\n",
    "\n",
    "from scipy import ndimage\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import numpy.ma as ma\n",
    "\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to calculate\n",
    "1.\tnucleus_DAPI_total\n",
    "2.\touter_DAPI_total\n",
    "3.\tinner_DAPI_total\n",
    "4.\tnucleus_DAPI_hetChrom\n",
    "5.\touter_DAPI_hetChrom\n",
    "6.\tinner_DAPI_hetChrom\n",
    "7.\tnucleus_DAPI_euChrom\n",
    "8.\touter_DAPI_euChrom\n",
    "9.\tinner_DAPI_euChrom\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gathering files\n",
    "deleting the columns with the signals to recalculate and collect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h3k9me3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigDir=r'Z:\\CookLab\\Liu\\20190816_organizedData_MCM_loading\\20200604_h3k9me3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=f'{bigDir}\\\\cellinfo_200604v4_10percent.csv'\n",
    "data=pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2=f'{bigDir}\\\\cellinfo_200604v4_50percent.csv'\n",
    "data2=pd.read_csv(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h3k9me3 2nd dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigDir=r'Z:\\CookLab\\Liu\\20190816_organizedData_MCM_loading\\20200615_h3k9me3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3=f'{bigDir}\\\\cellinfo_200615v4_10percent.csv'\n",
    "data3=pd.read_csv(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file4=f'{bigDir}\\\\cellinfo_200615v4_50percent.csv'\n",
    "data4=pd.read_csv(file4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h3k9me3 3rd dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigDir=r'Z:\\CookLab\\Liu\\20190816_organizedData_MCM_loading\\20200829_h3k9me3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAPI calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_DAPI_signals (data,percentage):\n",
    "    # progress bar\n",
    "    i=0\n",
    "    progBar=widgets.IntProgress(\n",
    "        value=i,\n",
    "        min=0,\n",
    "        max=len(data),\n",
    "        step=1,\n",
    "        description='Progress:',\n",
    "        orientation='horizontal'\n",
    "    )\n",
    "    display(progBar)\n",
    "    percentageCpy= percentage\n",
    "    \n",
    "    for i,myCell in islice(data.iterrows(), i,None):\n",
    "        if myCell.group=='CTL':\n",
    "            percentage = 20\n",
    "        ## opening cell image\n",
    "        try:\n",
    "            myImage=imread(myCell.path) \n",
    "        except:\n",
    "            myCell.path=myCell.path.replace('.tif','.tiff')\n",
    "            myImage=imread(myCell.path)\n",
    "        \n",
    "        ## channel for DAPI calculations is 2 for both datasets\n",
    "        myChannel=myImage[:,2,:,:]\n",
    "        \n",
    "        \n",
    "\n",
    "        ## setting arrays for names \n",
    "        \n",
    "        ### for column names\n",
    "        pixels=['total','het','eu']\n",
    "        components=['nuc','inner','outer']\n",
    "        \n",
    "        ### for masks names\n",
    "        dirs=['segmentation_nucleus_Otsu','erosion_nuc_mask','erosion_nuc_mask',\n",
    "              f'segmentation_{percentage}',f'segmentation_{percentage}_erosion',f'segmentation_{percentage}_erosion',\n",
    "             f'segmentation_{percentage}_eu',f'segmentation_{percentage}_eu_erosion',f'segmentation_{percentage}_eu_erosion',]\n",
    "\n",
    "        files=['_nucleus.tif','_eroded_9^5_inner_mask_20.tif','_eroded_9^5_outer_mask_20.tif',\n",
    "                   '_hetChrom.tif', '_hetChrom_inner.tif', '_hetChrom_outer.tif',\n",
    "                   '_euChrom.tif', '_euChrom_inner.tif','_euChrom_outer.tif']\n",
    "\n",
    "        df=pd.DataFrame(columns=['nuc_vol_total','inner_vol_total','outer_vol_total',\n",
    "                                 'nuc_mcm_total','inner_mcm_total','outer_mcm_total',\n",
    "                                'nuc_vol_het','inner_vol_het','outer_vol_het',\n",
    "                                 'nuc_mcm_het','inner_mcm_het','outer_mcm_het',\n",
    "                                 'nuc_vol_eu','inner_vol_eu','outer_vol_eu',\n",
    "                                'nuc_mcm_eu','inner_mcm_eu', 'outer_mcm_eu'])\n",
    "\n",
    "        ## calculating signals\n",
    "        for k in range(len(pixels)):\n",
    "            for j in range(len(components)):\n",
    "                ## copying image every time new signal is calculated\n",
    "                myIm=myImage.copy()\n",
    "                myChannel=myIm[:,2,:,:]\n",
    "                \n",
    "                ## column name set up based on the component and the pixels\n",
    "                currColName=f'{components[j]}_DAPI_{pixels[k]}'\n",
    "\n",
    "                ## opening mask images\n",
    "                ### the indexing is in such way so that the image opened matches up with the name being used for calculation\n",
    "                direc=myCell.path.replace('data_tiff',dirs[(j)+(k*3)])\n",
    "                try:\n",
    "                    direc=direc.replace('.tif',files[(k*3)+(j)])\n",
    "                    mask=imread(direc)  \n",
    "                except:\n",
    "                    direc=direc.replace('_nucleus.tiff',files[(k*3)+(j)])\n",
    "                    mask=imread(direc)\n",
    "\n",
    "                ## making the mask as binary\n",
    "                mask=mask.astype(bool)\n",
    "                \n",
    "                ## masking the image with the mask\n",
    "                myChannel[~mask]=0\n",
    "                \n",
    "                ## calculating signals\n",
    "                df[f'{currColName}']=myChannel.sum(-1).sum(-1)\n",
    "        \n",
    "        ## saving signals into original/big dataframe\n",
    "        for myMeasurement in df.columns:\n",
    "            myString=f\"data.loc[i,'{myMeasurement}']=np.sum(df.{myMeasurement})\"\n",
    "            exec(myString)\n",
    "            \n",
    "        percentage = percentageCpy\n",
    "        \n",
    "        progBar.value=progBar.value+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0596551799484d4ab063b7b88ec67b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=114)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8c2f77bb174a3c8ca57742672abc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=114)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f141dfdcda444f30964ad242a575158a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=114)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bd70d0cfa442828dceb6f7243398d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=114)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454034fbce204c4ab4bae0c82bc1f962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=114)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870503c6fd714b1f8a5201487d0ea726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=114)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d=(10,20,30,40,50,60)\n",
    "for i in d:\n",
    "    file=f'{bigDir}\\\\200819_cellinfo_v3_{i}.csv'\n",
    "    data=pd.read_csv(file)\n",
    "    ## calculating signals for original dataset\n",
    "    calculate_DAPI_signals(data,i)\n",
    "    data.to_csv(file.replace('v3','v4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4dec2f214641f880f6fe2d314ecc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=78)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## calculating signals for original dataset\n",
    "calculate_DAPI_signals(data,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking to see if the calculations resulted in what we have expected\n",
    "(np.sum(data['inner_DAPI_total'])+np.sum(data['outer_DAPI_total']))/np.sum(data['nuc_DAPI_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "## checking to see if the calculations resulted in what we have expected\n",
    "print((np.sum(data['inner_DAPI_het'])+np.sum(data['outer_DAPI_het']))/np.sum(data['nuc_DAPI_het']),\n",
    "(np.sum(data['inner_DAPI_eu'])+np.sum(data['outer_DAPI_eu']))/np.sum(data['nuc_DAPI_eu']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the dataset with calculated signals\n",
    "data.to_csv(file.replace('v4','v5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36dec8b6f884b3f97f0d78d9ad15162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=78)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## calculating signals for original dataset\n",
    "calculate_DAPI_signals(data2,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking to see if the calculations resulted in what we have expected\n",
    "(np.sum(data2['inner_DAPI_total'])+np.sum(data2['outer_DAPI_total']))/np.sum(data2['nuc_DAPI_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "## checking to see if the calculations resulted in what we have expected\n",
    "print((np.sum(data2['inner_DAPI_het'])+np.sum(data2['outer_DAPI_het']))/np.sum(data2['nuc_DAPI_het']),\n",
    "(np.sum(data2['inner_DAPI_eu'])+np.sum(data2['outer_DAPI_eu']))/np.sum(data2['nuc_DAPI_eu']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the dataset with calculated signals\n",
    "data2.to_csv(file2.replace('v4','v5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8dce5b6ece44bfca0b837bc875d386d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=88)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## calculating signals for original dataset\n",
    "calculate_DAPI_signals(data3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking to see if the calculations resulted in what we have expected\n",
    "(np.sum(data3['inner_DAPI_total'])+np.sum(data3['outer_DAPI_total']))/np.sum(data3['nuc_DAPI_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "## checking to see if the calculations resulted in what we have expected\n",
    "print((np.sum(data3['inner_DAPI_het'])+np.sum(data3['outer_DAPI_het']))/np.sum(data3['nuc_DAPI_het']),\n",
    "(np.sum(data3['inner_DAPI_eu'])+np.sum(data3['outer_DAPI_eu']))/np.sum(data3['nuc_DAPI_eu']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the dataset with calculated signals\n",
    "data3.to_csv(file3.replace('v4','v5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2a2a6b4fe54388a7c579d29d6823f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=88)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## calculating signals for original dataset\n",
    "calculate_DAPI_signals(data4,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking to see if the calculations resulted in what we have expected\n",
    "(np.sum(data4['inner_DAPI_total'])+np.sum(data4['outer_DAPI_total']))/np.sum(data4['nuc_DAPI_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "## checking to see if the calculations resulted in what we have expected\n",
    "print((np.sum(data4['inner_DAPI_het'])+np.sum(data4['outer_DAPI_het']))/np.sum(data4['nuc_DAPI_het']),\n",
    "(np.sum(data4['inner_DAPI_eu'])+np.sum(data4['outer_DAPI_eu']))/np.sum(data4['nuc_DAPI_eu']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the dataset with calculated signals\n",
    "data4.to_csv(file4.replace('v4','v5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
